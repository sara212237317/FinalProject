hello my name is juan gomez luna and i'm a senior researcher in the safari research group at eta zurich i'm going to present our work understanding a modern processing in memory architecture benchmarking and experimental characterization let's start with a brief executive summary in current computing systems data movement between the memory and storage units and the compute units is a major contributor to the execution time and the energy consumption processing in memory is a promising paradigm that can tackle this data movement bottleneck processing in memory essentially consists of placing compute capabilities near or inside memory all to explore for more than 50 years technology challenges prevented from the successful materialization upm has designed fabricated and commercializes the first publicly available real-world processing in memory architecture which consists of ddr4 chips embedding a small cores called dram processing units or gpus or work is an introduction to the upm team architecture and programming model a characterization of the vpu architecture and a benchmarking and workload suitability study our main contributions are a comprehensive characterization and analysis of the first commercially available team architecture and the first benchmark suite for a real-world processing memory architecture that is called prim prim contains 16 workloads that are memory bound in conventional processor centric systems we characterize these workloads with a strong and weak scaling analysis and compare them to their state-of-the-art cpu and gpu counterparts main takeaways of our work are the order characteristics for pin suitability programming recommendations suggestions and machines for hardware architecture designers of future pin systems and prim which can be used as programming samples and for evaluation and comparison of current and future pin systems data movement in current compute systems dominates performance and energy consumption according to wrestling studies data movement accounts for 62 percent of total system energy in consumer applications 40 in scientific applications and 35 in mobile applications if you take a look at a current system on shift you will find many components like cpu gpu hash hierarchy accelerators and among all these components and the dram there is a lot of data movement this data movement entails a huge bottleneck that can be alleviated by making compute systems more data centric and processing memory is a way of doing it processing in memory proposes computing where it makes sense where the data resides the opm team architecture consists of ddr4 beams with fin chips that contain memory arrays and small processors called gpus in our paper we present this architecture and perform a thorough benchmarking and an experimental characterization throughout all paper and also throughout this presentation you will find some color boxes with programming recommendations key observations and key takeaways let's start with an overview of a upman-based pin system the integration of up mendings in a system follows the accelerator model where the upmds are seen as an accelerator or a co-processor in this model the data movement needs to happen between the host main mem the main memory the the host processor and the accelerator and this data movement needs to be explicit also explicit needs to be the kernel launch onto the upm processors being the kernel the function that is going to be executed onto these you payment processors as bpus this resembles gpu computing typical system organization is something like this with a whole cpu connected to some dram beams that represent the main memory and some eukman dims that represent the team enabled memory inside each up and dim there are 8 or 16 chips which means one or two ranks of eight chips each and if we take a closer look at the pin chip we will find some dram banks that are called nram of size 64 megabytes and eight dram processing units in total there are 64 gpus per rank and also 64 mran banks in our work we have used a system with 20 upmandims that features up to 2500 dpus and 160 gigabytes of bim enabled memory we have also used a smaller system with 640 gpus and 40 gigabytes of bim enabled memory can give a few hints about upman programming and about the interaction between the cpu and the dbus our first programming example is vector addition one of our benchmarks in vector addition we perform the element wise addition of two input vectors a and b and store the result in a vector c what we do in the euphemism-based pin system is partitioning the arrays across gpus and also inside each of the dpu we have software threads running that are called tasklets that process the data that has been assigned to each tpu the cpu communicates with the dpus via transfers from main memory to the bim enable memory that we call cpu dpu transfers and transfers from the pim enabled memory to the main memory that we call dpu cpu transfers there are three types of these transfers there are serial transfers when we are targeting a single dbu and a single embryon bank there are parallel transfers when we perform the transfer to multiple dpus at the same time and there are broadcast transfers when we transfer a single buffer to multiple gpus there is no direct communication channel between dbus and this means that inter gpu communication takes place via the host cpu using cpu gpu and dpu cpu transfers that obviously entail an important overhead there are some example communication patterns among our benchmarks for example merging of partial results to obtain the final result or redistribution of intermediate results or further computation how fast are these transfers we measure these using uh two micro benchmarks and two experiments in the first of our experiments we use a single dpu and we vary the transfer size from eight bytes to 32 megabytes so here we see the results for the bandwidth results for cpu gpu transfers for dpu cpu transfers and a key observation means that larger cpu gpu and dpu cpu transfers between the host main memory and the m-ram banks result in higher sustained bandwidth we also run experiments on one rank in this case we vary the number of gpus from 1 to 64. these are the bandwidth results for serial transfers these are the bandwidth results for parallel and broadcast transfers and one key observation is that the sustained bandwidth of parallel cpu gpu and gpu cpu transfers between the host main memory and the mram banks increases with the number of gpus inside a rank now let's take a close look at the drum processing unit and characterize it so if we take a look inside a pinchy we will find a ddr4 interface for the host to access the ram banks we have a control status interface for the host to send commands to the dpus we find eight of these dram banks called engram of size 64 megabytes and a dvma engine to access it we have two sram based memories one for instructions and one and one for operands called wram and we have the dpu pipeline this dpu pipeline is an in-order pipeline and today it can run at a frequency of up to 350 megahertz it's a fine-grained multi-threaded architecture with up to 24 hardware threads and contains 14 pipeline stages we measure the arithmetic throughput for different data types and operations what we do is reading an array moving it to wrap and streaming over this array performing read modify write operations we run our experiments on a single gpu these are the results for integers 32 and 64 bit values and these are the results for float and double values these are the results for and subtraction and these for multiplication and division and these are the results for the rest of data types one key observation is that in all cases the throat put saturates at 11 or more tasklets and this observation is consistent across data types and operations another observation is that there is a large throughput difference between integer and floating point and also between addition subtraction and multiplication division the reason is that bpus provide native support for 32 and 64-bit integration and subtraction leading to high throughput while they don't have native support for multiplication division floating point operations these operations are emulated by the eup memorandal library which leads to much lower throughput in our paper we also analyze the access to wrap but now let's take a look at the access to mram we measure the bandwidth to enron for different access patterns we use different micro benchmarks first we measure the latency of a single dma transfer then we show we also implement the string benchmark to measure the bandwidth of the string benchmark and benchmarks for strided and random access patterns let's start with the latency of a single dma transfer so here for different transfer sizes we are going to show the latency of pump and bandwidth of engram read and embrace right transfers the implant bandwidth can be obtained from this expression after after measuring the emblem latency one thing we notice is that we can model the engine latency with a linear expression something like this where the embryonic latency is equal to a fixed cost alpha and a variable cost beta times size being size the size of the transfer we notice that our model matches perfectly the mram latency measurements and according to our measurements this beta equals 0.5 cycles per byte this way the theoretical maximum embryon bandwidth is 700 megabytes per second and our measurements are quite close to that one key observation is that the m gram bank access latency increases linearly with the transfer size and also that the maximum theoretical engram bandwidth is 2 bytes per cycle now let's take a quick look at the results for the stream benchmark we have the four versions of the stream benchmark but we have two versions of the benchmark one thing we notice is that for some of these the throat put saturates at less than 11 tasklets while for others scale and triad the throat would saturate at 11. this is because when the access latency to an amgram bank for a streaming benchmark is larger than the pipeline latency the performance of the gpu saturates at a number of tasklets smaller than 11. this is a memory bound workload however when the pipeline latency for a streaming benchmark is larger than the mram access latency the performance of the gpu saturates at 11 tasklets this is a compute bound workload in the paper you can also find results for extradited and random access patterns now let's take a look at the arithmetic throughput versus the operational intensity in this experiment we want to characterize memory bound and compute bound regions for different data types and operations what we do is moving one chunk of data from engram to wrap performing a variable number of operations on the data and running by right back to embrace this is inspired by the roof line model that represents performance versus the arithmetic of operational intensity in our work we define operational intensity as the number of arithmetic operations performed per byte access from embraer the pipeline latency changes with the operational intensity in our experiments but the engram access latency is fixed we can take a look at a look at this result for addition of 32-bit elements and what we observe is that it is that there is a memory bound region where the arithmetic throughput increases with the operational intensity and there is a compute balanced region where the arithmetic throughput is flat at its maximum and saturates with 11 tasklets the throat called saturation point is the operational intensity where the transition between the memory bound and compute bound region happens and this throughput saturation point is very low it's actually very low for all data types and operations the arithmetic throughput of the dbu saturates at low or very low operational intensity and thus the dpu is fundamentally a compute bound processor so we expect that most real-world workloads will be compute bound in the uk and pim architecture let's take a look at the prime benchmarks the idea is to come up with a common set of workloads that can be used for different purposes like evaluating the opm team architecture comparing software improvement in compilers comparing future team architectures and hardware etc we use two selection criteria we select workloads from different domains and also workloads that are memory bound on conventional processors we have a total of 14 workloads and 16 different benchmarks if we take a look at the applications domain we will see dense and linear algebra databases graph processing neural networks bioinformatics etc all these workloads fall in the memory bound area of the roofline on a intelsion cpu and these workloads are also diverse they have different memory access patterns computation patterns and communication synchronization patterns either intra dpu or into the inter gpu we evaluate with strong and weak scaling experiments and also compare them to cpu and gpu we use two upm day systems in our evaluation and we have strong and weak scaling experiments on one dpu one rank and up to 32 ranks these oh we also compare to uh you can or we payment-based systems to cpu and gpu uh here you can see the results for a strong scaling of one dbu here we change the number of task lists from 1 to 16 and we show the breakdown of execution time for the dpu kernel time in the dpu synchronization time cpu dpu transfers gpu cpu transfers and also the speed up over one tesla some observations are that the best performing number of tasklets is typically 16 for most of the workloads and this leads us to this key observation a number of tasklets greater than 11 is a good choice for most real-world workloads another observation is that many of these some of these workloads don't need intra-dp using synchronization primitives and other synchronization is lightweight but in three of them where they use mutexes there is a lot of contention due to the access to shared data structures for example in one of our versions of histogram we have task let's inside the gpu updating a common histogram and because they need to use mutexes we see that the best performing number of tasklets is not 16 but eight due to the contention in the access to the shared histogram so intensive use of intradipu synchronization across tasklets like mutexes barriers or handshakes may limit the scalability and the best performing number of task leds may be lower than 11 in these cases the paper also shows results of strongly scaling on one rank on 32 ranks and weak scaling experiments you you can find a lot of insights and key observations for all these experiments in the paper now let's take a quick look at the comparisons to cpu and gpu these are the results for the performance comparison we have some workloads that we identify like more pin suitable some other benchmarks are less pin suitable and these are the geomet values so one key observation is that both euphemism-based pin systems outperform the cpu for all benchmarks as except three of them another observation is that the larger gpus utm based pin system outperforms the gpu for 10 prime benchmarks with an average of 2.54 times these 10 workloads have three key characteristics they use extremely memory accesses they have no more little inter gpu synchronization and they have no more little use of integral multiplication integral division and floating point operations these three characteristics make a workload potentially suitable to the upmp architecture we also have in the paper energy comparison and we and we show that for 12 benchmarks the 600 dpu system provide energy savings of 5.23 times over the cpu let's finish with some key takeaways so one observation in our paper is that the throughput saturation point is very low for all operations and data types so key takeaway one is that the up beams architecture is fundamentally compute bound and as a result most suitable workloads are memory bound in conventional processors another key takeaway is that the most well-suited workloads for the european beam architecture use no arithmetic operations or use only simple operations like bitwise or integer additional subtraction another key observation key takeaway is that most well-suited workloads for the opm team architecture require little or no communication across gpus what we call the internet gpu communication and key takeaway number four says that the upm based pin systems outperform a state-of-the-art cpus in terms of energy and performance on most spring benchmarks and they outperform gpus for a majority of prim benchmarks that have the three characteristics that we presented before and the outlook is even more positive for future pin systems the eukman-based pin systems are more energy efficient than state-of-the-art cpus and gpus on workloads that they provide performance improvements over cpu and gpu and the reason is that both the source of performance improvements and energy savings is the less data movement between memory and processors that processing and memory systems can provide so we know that data movement is a huge bottleneck in current computing systems processing in memory is a way of alleviating it and implementing is the first company that has fabricated and commercializes a real-world processing in memory architecture or work introduces this processing in memory architecture and programming model characterizes it and performs a benchmarking and world suitability study our main contributions are a comprehensive characterization and analysis of this architecture a new benchmark suite the first benchmark suite for a real-world processing in memory architecture with 16 workloads we have analyzed our workloads with strong weak scaling analysis and compared to cpu and gpu key takeaways of our work are the world characteristics for pin suitability programming recommendations suggestions and things for hardware and architecture designers of future pin systems and the print benchmark suite which can be used as programming samples and also for evaluation and comparison of current and future pin systems you can find all the details in all papers and all our codes micro benchmarks benchmarks and script are publicly available in our repository thank you very much for your attention
